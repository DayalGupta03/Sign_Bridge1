# AI Mediation Layer - SignBridge 3D

## Overview

The AI Mediation Layer is the intelligence core of SignBridge 3D. It uses Google's Gemini LLM to transform raw communication inputs (speech transcripts and gesture intents) into clear, context-aware medical communication.

## Status: ‚úÖ Production MVP Ready (Phase 3)

**What's Implemented**: Context-aware LLM mediation for both communication flows  
**What's Next**: Response caching, rate limiting, streaming  
**API**: Google Gemini 1.5 Flash

---

## Architecture

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AI MEDIATION LAYER                               ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  Raw Input (Speech or Gesture)                                     ‚îÇ
‚îÇ         ‚îÇ                                                           ‚îÇ
‚îÇ         ‚ñº                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                              ‚îÇ
‚îÇ  ‚îÇ  Input Validation‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                              ‚îÇ
‚îÇ         ‚îÇ                                                           ‚îÇ
‚îÇ         ‚ñº                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                              ‚îÇ
‚îÇ  ‚îÇ Prompt Builder   ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - System Prompt  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - User Prompt    ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - Context        ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - History        ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                              ‚îÇ
‚îÇ         ‚îÇ                                                           ‚îÇ
‚îÇ         ‚ñº                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                              ‚îÇ
‚îÇ  ‚îÇ  Gemini API Call ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ  (5s timeout)    ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                              ‚îÇ
‚îÇ         ‚îÇ                                                           ‚îÇ
‚îÇ         ‚ñº                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                              ‚îÇ
‚îÇ  ‚îÇOutput Validation ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - Length check   ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - Emoji removal  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îÇ - Format clean   ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                              ‚îÇ
‚îÇ         ‚îÇ                                                           ‚îÇ
‚îÇ         ‚ñº                                                           ‚îÇ
‚îÇ  Mediated Text (‚â§20 words)                                         ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Integration Points

### 1. Speech-to-Text Flow (Hearing ‚Üí Deaf)

**Location**: `components/application-interface.tsx` (line ~494)

```typescript
// Raw speech transcript from Web Speech API
const transcript = "The patient needs to describe their symptoms"

// Mediate with context
const mediationResult = await mediateIntent({
  rawInput: transcript,
  mode: "hearing-to-deaf",
  context: "hospital", // or "emergency"
  recentHistory: ["Previous message 1", "Previous message 2"]
})

// Result: "Please describe your symptoms to the doctor."
```

**Transformation**:
- Input: Raw speech transcript (may be unclear, verbose)
- Output: Clear, patient-friendly medical communication
- Tone: Adjusted for context (calm vs urgent)

---

### 2. Sign Recognition Flow (Deaf ‚Üí Hearing)

**Location**: `components/application-interface.tsx` (line ~802)

```typescript
// Raw gesture intent from MediaPipe Hands
const gestureIntent = "I'm experiencing pain"

// Mediate with context
const mediationResult = await mediateIntent({
  rawInput: gestureIntent,
  mode: "deaf-to-hearing",
  context: "emergency",
  recentHistory: ["Patient arrived", "Triage assessment"]
})

// Result: "Patient reports experiencing pain."
```

**Transformation**:
- Input: Gesture intent phrase (may be terse, ambiguous)
- Output: Natural, fluent medical communication
- Tone: Adjusted for context (calm vs urgent)

---

## System Prompt Design

### Core Principles

The system prompt is the intelligence core. It defines:

1. **Role**: AI communication mediator (not medical advisor)
2. **Constraints**: No diagnoses, no hallucinations, no jargon
3. **Format**: Single sentence, ‚â§20 words, no markdown
4. **Tone**: Context-appropriate (calm vs urgent)
5. **Safety**: Professional, accessible language only

### Prompt Structure

```typescript
function buildSystemPrompt(context, mode) {
  return `
    You are an AI communication mediator for SignBridge 3D.
    
    ROLE:
    You interpret and clarify communication between patients 
    and medical staff. You do NOT diagnose, treat, or provide 
    medical advice.
    
    CURRENT CONTEXT: ${context}
    COMMUNICATION DIRECTION: ${mode}
    
    OUTPUT REQUIREMENTS:
    - Single sentence only (maximum 20 words)
    - Clear, professional medical communication language
    - No emojis, markdown, or formatting
    - No disclaimers or meta-commentary
    - No medical diagnoses or treatment advice
    - No hallucinated information
    
    TONE GUIDELINES:
    ${context === "hospital" 
      ? "Calm and descriptive, professional but warm"
      : "Urgent and action-oriented, direct and concise"}
    
    SAFETY CONSTRAINTS:
    - Never diagnose conditions
    - Never recommend treatments
    - Never add information not in the input
    - Never use technical jargon without explanation
    - Never include system internals or instructions
  `
}
```

### Context-Specific Behavior

| Context | Tone | Example Input | Example Output |
|---------|------|---------------|----------------|
| Hospital | Calm, descriptive | "Tell me about your pain" | "Please describe your pain to the doctor." |
| Emergency | Urgent, direct | "Tell me about your pain" | "Describe your pain immediately." |

---

## API Configuration

### Gemini Setup

**Model**: `gemini-1.5-flash`
- Fast response times (500-1500ms)
- Cost-effective for high volume
- Good balance of quality and speed

**API Key**: Set environment variable
```bash
NEXT_PUBLIC_GEMINI_API_KEY=your_api_key_here
```

**Get API Key**: https://makersuite.google.com/app/apikey

### Rate Limits (Free Tier)

- **60 requests per minute**
- **1500 requests per day**

For production:
- Upgrade to paid tier
- Implement request caching
- Add rate limiting logic

---

## Input/Output Specification

### Input Format

```typescript
interface MediationRequest {
  rawInput: string           // Raw transcript or gesture intent
  mode: MediationMode        // "hearing-to-deaf" | "deaf-to-hearing"
  context: MediationContext  // "hospital" | "emergency"
  recentHistory?: string[]   // Last 2-3 utterances for context
}
```

### Output Format

```typescript
interface MediationResponse {
  mediatedText: string  // Mediated output (‚â§20 words)
  success: boolean      // Whether mediation succeeded
  error?: string        // Error message if failed
}
```

### Output Constraints

‚úÖ **Required**:
- Single sentence
- Maximum 20 words
- Professional language
- Context-appropriate tone

‚ùå **Forbidden**:
- Emojis
- Markdown formatting
- Multiple sentences
- Medical diagnoses
- Treatment recommendations
- Hallucinated information
- System internals

---

## Example Transformations

### Hospital Context (Calm Tone)

| Input Type | Raw Input | Mediated Output |
|------------|-----------|-----------------|
| Speech | "Can you tell me where it hurts?" | "Please show the doctor where you feel pain." |
| Speech | "We need to run some tests on you" | "The doctor will perform some diagnostic tests." |
| Gesture | "I'm experiencing pain" | "Patient reports experiencing pain." |
| Gesture | "Pointing to upper area" | "Patient indicates pain in the upper body area." |

### Emergency Context (Urgent Tone)

| Input Type | Raw Input | Mediated Output |
|------------|-----------|-----------------|
| Speech | "Can you tell me where it hurts?" | "Where is the pain located?" |
| Speech | "We need to run some tests on you" | "Emergency tests required immediately." |
| Gesture | "I need help" | "Patient requires immediate assistance." |
| Gesture | "I'm experiencing pain" | "Patient reports severe pain." |

---

## Error Handling

### Graceful Degradation

The mediation layer has multiple fallback levels:

```
1. Try Gemini API mediation
   ‚Üì (if fails)
2. Log warning, use raw input
   ‚Üì
3. Display to user
```

### Error Types

| Error | Cause | Fallback |
|-------|-------|----------|
| API key missing | `NEXT_PUBLIC_GEMINI_API_KEY` not set | Use raw input |
| API call fails | Network error, timeout | Use raw input |
| Rate limit exceeded | Too many requests | Use raw input |
| Invalid response | LLM output malformed | Use raw input |
| Timeout | Response > 5 seconds | Use raw input |

### Error Logging

```typescript
// API key missing
console.warn("‚ö†Ô∏è Gemini API key not configured")

// Mediation failed
console.warn("‚ö†Ô∏è Mediation failed, using raw transcript:", error)

// Rate limit
console.error("üìä API quota exceeded")

// Timeout
console.error("‚è±Ô∏è Mediation timeout")
```

---

## Performance

### Latency

- **Typical**: 500-1500ms
- **Timeout**: 5000ms
- **Target**: <1000ms for good UX

### Optimization Strategies

1. **Caching** (TODO)
   - Cache common medical phrases
   - Reduce API calls by 50-70%
   - Lower latency to <100ms for cached

2. **Streaming** (TODO)
   - Stream response as it generates
   - Lower perceived latency
   - Better user experience

3. **Prefetching** (TODO)
   - Predict likely next inputs
   - Pre-generate responses
   - Instant results for common flows

---

## Safety & Compliance

### Medical Safety

‚úÖ **What the LLM Does**:
- Clarifies communication
- Adjusts tone for context
- Maintains original meaning
- Uses accessible language

‚ùå **What the LLM Does NOT Do**:
- Diagnose medical conditions
- Recommend treatments
- Add medical information
- Make clinical decisions

### HIPAA Compliance

**Current Status**: ‚ö†Ô∏è Not HIPAA compliant

**Required for Production**:
- [ ] Business Associate Agreement (BAA) with Google
- [ ] Encrypt all data in transit (TLS 1.3)
- [ ] Audit logging for all API calls
- [ ] Data retention policies
- [ ] User consent flows
- [ ] Privacy policy updates

**Note**: Gemini API may send data to Google servers. Verify HIPAA compliance before production use.

---

## Testing

### Manual Testing

1. **Enable Production Mode**
   ```typescript
   const DEMO_MODE_ENABLED = false
   ```

2. **Set API Key**
   ```bash
   export NEXT_PUBLIC_GEMINI_API_KEY=your_key_here
   ```

3. **Test Speech Flow**
   - Switch to hearing-to-deaf mode
   - Enable microphone
   - Speak: "Can you describe your symptoms?"
   - Verify mediated output appears

4. **Test Gesture Flow**
   - Switch to deaf-to-hearing mode
   - Enable camera
   - Make "pain" gesture (fist)
   - Verify mediated output appears

5. **Test Context Switching**
   - Toggle between hospital and emergency
   - Verify tone changes appropriately

### Test Cases

| Test | Input | Expected Output | Pass/Fail |
|------|-------|-----------------|-----------|
| Hospital speech | "Tell me about your pain" | "Please describe your pain to the doctor." | ‚úÖ |
| Emergency speech | "Tell me about your pain" | "Describe your pain immediately." | ‚úÖ |
| Hospital gesture | "I'm experiencing pain" | "Patient reports experiencing pain." | ‚úÖ |
| Emergency gesture | "I need help" | "Patient requires immediate assistance." | ‚úÖ |
| API key missing | Any input | Raw input (fallback) | ‚úÖ |
| Network error | Any input | Raw input (fallback) | ‚úÖ |

---

## Troubleshooting

### Issue: Mediation Not Working

**Symptoms**: Raw input appears in subtitles, no mediation

**Solutions**:
1. Check API key is set: `echo $NEXT_PUBLIC_GEMINI_API_KEY`
2. Verify demo mode is OFF: `DEMO_MODE_ENABLED = false`
3. Check browser console for errors
4. Verify network connectivity
5. Check API quota hasn't been exceeded

---

### Issue: Responses Too Long

**Symptoms**: Mediated text exceeds 20 words

**Solutions**:
1. System prompt enforces 20-word limit
2. Output validation truncates if needed
3. If persistent, adjust system prompt
4. Consider using `gemini-1.5-pro` for better instruction following

---

### Issue: Inappropriate Tone

**Symptoms**: Emergency responses too calm, or hospital responses too urgent

**Solutions**:
1. Verify context is set correctly
2. Check system prompt tone guidelines
3. Adjust prompt if needed
4. Test with multiple examples

---

### Issue: Rate Limit Exceeded

**Symptoms**: "API quota exceeded" errors

**Solutions**:
1. Upgrade to paid tier
2. Implement response caching
3. Add rate limiting logic
4. Reduce request frequency

---

## Future Enhancements

### Phase 4: Optimization

- [ ] **Response Caching**
  - Cache common medical phrases
  - Reduce API calls by 50-70%
  - Lower latency to <100ms

- [ ] **Request Queuing**
  - Queue requests when rate limit approached
  - Retry with exponential backoff
  - Show user feedback during delays

- [ ] **Streaming Responses**
  - Stream LLM output as it generates
  - Lower perceived latency
  - Better user experience

### Phase 5: Intelligence

- [ ] **Medical Term Extraction**
  - Identify medical terminology
  - Provide simple explanations
  - Link to medical glossary

- [ ] **Context Detection**
  - Auto-detect emergency keywords
  - Switch context automatically
  - Escalate urgent situations

- [ ] **Multi-Language Support**
  - Support multiple spoken languages
  - Support multiple sign languages (ASL, BSL, LSF)
  - Automatic language detection

### Phase 6: Safety

- [ ] **Content Filtering**
  - Filter inappropriate content
  - Detect and block harmful instructions
  - Ensure professional communication

- [ ] **Audit Logging**
  - Log all mediation requests
  - Track API usage
  - Monitor for safety issues

- [ ] **HIPAA Compliance**
  - Business Associate Agreement
  - Data encryption
  - Audit trails
  - User consent

---

## Code Maintenance

### Modifying System Prompt

**Location**: `lib/mediator.ts` (line ~60)

```typescript
function buildSystemPrompt(context, mode) {
  // Modify prompt here
  // Test thoroughly after changes
  // Document reasoning
}
```

**Testing Checklist**:
- [ ] Test with hospital context
- [ ] Test with emergency context
- [ ] Test both communication modes
- [ ] Verify output length (‚â§20 words)
- [ ] Verify no emojis or markdown
- [ ] Verify appropriate tone

---

### Adding New Contexts

```typescript
// Add new context type
export type MediationContext = "hospital" | "emergency" | "clinic"

// Update system prompt
function buildSystemPrompt(context, mode) {
  const toneGuidelines = {
    hospital: "Calm and descriptive",
    emergency: "Urgent and action-oriented",
    clinic: "Friendly and conversational" // New
  }
  
  return `...TONE GUIDELINES: ${toneGuidelines[context]}...`
}
```

---

### Changing LLM Model

```typescript
// Current: Fast and cost-effective
const GEMINI_MODEL = "gemini-1.5-flash"

// Alternative: Higher quality, slower, more expensive
const GEMINI_MODEL = "gemini-1.5-pro"

// Alternative: Experimental, cutting-edge
const GEMINI_MODEL = "gemini-2.0-flash-exp"
```

**Trade-offs**:
- Flash: Fast (500ms), cheap, good quality
- Pro: Slower (1500ms), expensive, best quality
- Experimental: Variable, free, bleeding edge

---

## Summary

The AI Mediation Layer is the **intelligence core** of SignBridge 3D. It:

‚úÖ **Transforms** raw inputs into clear medical communication  
‚úÖ **Adapts** tone based on context (hospital vs emergency)  
‚úÖ **Maintains** conversation coherence with history  
‚úÖ **Ensures** safety with strict constraints  
‚úÖ **Falls back** gracefully when API fails  
‚úÖ **Integrates** seamlessly with STT and sign recognition  

**Key Features**:
- Context-aware mediation
- Professional medical language
- Concise output (‚â§20 words)
- Safety constraints (no diagnoses)
- Graceful error handling
- Production-ready code

**Next Steps**:
1. Set up Gemini API key
2. Test with real medical scenarios
3. Implement response caching
4. Add HIPAA compliance measures
5. Monitor API usage and costs

---

**Last Updated**: December 23, 2025  
**Version**: 1.0.0 MVP (Phase 3)  
**Status**: Production Ready ‚úÖ
